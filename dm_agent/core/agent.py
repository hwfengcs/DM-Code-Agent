"""ç”± LLM API é©±åŠ¨çš„ ReAct é£æ ¼æ™ºèƒ½ä½“ã€‚"""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional

from ..clients.base_client import BaseLLMClient
from ..tools.base import Tool
from ..prompts import build_code_agent_prompt
from ..memory.context_compressor import ContextCompressor
from .planner import TaskPlanner, PlanStep


@dataclass
class Step:
    """è¡¨ç¤ºæ™ºèƒ½ä½“çš„ä¸€ä¸ªæ¨ç†æ­¥éª¤ã€‚"""

    thought: str
    action: str
    action_input: Any
    observation: str
    raw: str = ""


class ReactAgent:
    """ä½¿ç”¨ LLM è¿›è¡Œè§„åˆ’çš„ç®€å• ReActï¼ˆæ¨ç†+è¡ŒåŠ¨ï¼‰æ™ºèƒ½ä½“ã€‚"""

    def __init__(
        self,
        client: BaseLLMClient,
        tools: List[Tool],
        *,
        max_steps: int = 200,
        temperature: float = 0.0,
        system_prompt: Optional[str] = None,
        step_callback: Optional[Callable[[int, Step], None]] = None,
        enable_planning: bool = True,
        enable_compression: bool = True,
    ) -> None:
        if not tools:
            raise ValueError("å¿…é¡»ä¸º ReactAgent æä¾›è‡³å°‘ä¸€ä¸ªå·¥å…·ã€‚")
        self.client = client
        self.tools = {tool.name: tool for tool in tools}
        self.tools_list = tools  # ä¿ç•™å·¥å…·åˆ—è¡¨ç”¨äºè§„åˆ’å™¨
        self.max_steps = max_steps
        self.temperature = temperature
        self.system_prompt = system_prompt or build_code_agent_prompt(tools)
        self.step_callback = step_callback
        # å¤šè½®å¯¹è¯å†å²è®°å½•
        self.conversation_history: List[Dict[str, str]] = []

        # è§„åˆ’å™¨
        self.enable_planning = enable_planning
        self.planner = TaskPlanner(client, tools) if enable_planning else None

        # ä¸Šä¸‹æ–‡å‹ç¼©å™¨ï¼ˆæ¯ 5 è½®å¯¹è¯å‹ç¼©ä¸€æ¬¡ï¼‰
        self.enable_compression = enable_compression
        self.compressor = ContextCompressor(client, compress_every=5, keep_recent=3) if enable_compression else None

    def run(self, task: str, *, max_steps: Optional[int] = None) -> Dict[str, Any]:
        if not isinstance(task, str) or not task.strip():
            raise ValueError("ä»»åŠ¡å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ã€‚")

        steps: List[Step] = []
        limit = max_steps or self.max_steps

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆè®¡åˆ’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        plan = []
        if self.enable_planning and self.planner:
            try:
                plan = self.planner.plan(task)
                if plan:
                    plan_text = self.planner.get_progress()
                    print(f"\nğŸ“‹ ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’ï¼š\n{plan_text}")
            except Exception as e:
                print(f"âš ï¸ è®¡åˆ’ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼Œå°†ä½¿ç”¨å¸¸è§„æ¨¡å¼æ‰§è¡Œ")

        # æ·»åŠ æ–°ä»»åŠ¡åˆ°å¯¹è¯å†å²
        task_prompt = self._build_user_prompt(task, steps, plan)
        self.conversation_history.append({"role": "user", "content": task_prompt})

        for step_num in range(1, limit + 1):
            # ç¬¬äºŒæ­¥ï¼šå‹ç¼©ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            messages_to_send = [{"role": "system", "content": self.system_prompt}] + self.conversation_history

            if self.enable_compression and self.compressor:
                if self.compressor.should_compress(self.conversation_history):
                    print(f"\nğŸ—œï¸ å‹ç¼©å¯¹è¯å†å²ä»¥èŠ‚çœ token...")
                    compressed_history = self.compressor.compress(self.conversation_history)
                    messages_to_send = [{"role": "system", "content": self.system_prompt}] + compressed_history

                    # æ˜¾ç¤ºå‹ç¼©ç»Ÿè®¡
                    stats = self.compressor.get_compression_stats(
                        self.conversation_history, compressed_history
                    )
                    print(
                        f"   å‹ç¼©ç‡ï¼š{stats['compression_ratio']:.1%}ï¼Œ"
                        f"èŠ‚çœ {stats['saved_messages']} æ¡æ¶ˆæ¯"
                    )

            raw = self.client.respond(messages_to_send, temperature=self.temperature)

            # å°† AI å“åº”æ·»åŠ åˆ°å†å²è®°å½•
            self.conversation_history.append({"role": "assistant", "content": raw})
            try:
                parsed = self._parse_agent_response(raw)
            except ValueError as exc:
                observation = f"è§£ææ™ºèƒ½ä½“å“åº”å¤±è´¥ï¼š{exc}"
                step = Step(
                    thought="",
                    action="error",
                    action_input={},
                    observation=observation,
                    raw=raw,
                )
                steps.append(step)

                # å°†é”™è¯¯è§‚å¯Ÿæ·»åŠ åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"è§‚å¯Ÿï¼š{observation}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                continue

            action = parsed.get("action", "").strip()
            thought = parsed.get("thought", "").strip()
            action_input = parsed.get("action_input")

            if action == "finish":
                final = self._format_final_answer(action_input)
                step = Step(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation="<finished>",
                    raw=raw,
                )
                steps.append(step)

                # æ·»åŠ å®Œæˆæ ‡è®°åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"ä»»åŠ¡å®Œæˆï¼š{final}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                return {"final_answer": final, "steps": [step.__dict__ for step in steps]}

            tool = self.tools.get(action)
            if tool is None:
                observation = f"æœªçŸ¥å·¥å…· '{action}'ã€‚"
                step = Step(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation=observation,
                    raw=raw,
                )
                steps.append(step)

                # å°†è§‚å¯Ÿç»“æœæ·»åŠ åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"è§‚å¯Ÿï¼š{observation}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                continue

            # task_complete å·¥å…·å¯ä»¥æ¥å—å­—ç¬¦ä¸²æˆ–ç©ºå‚æ•°
            if action == "task_complete":
                if action_input is None:
                    action_input = {}
                elif isinstance(action_input, str):
                    action_input = {"message": action_input}
                elif not isinstance(action_input, dict):
                    action_input = {}
                try:
                    observation = tool.execute(action_input)
                except Exception as exc:  # noqa: BLE001 - å°†å·¥å…·é”™è¯¯ä¼ é€’ç»™ LLM
                    observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{exc}"
            elif action_input is None:
                observation = "å·¥å…·å‚æ•°ç¼ºå¤±ï¼ˆaction_input ä¸º nullï¼‰ã€‚"
            elif not isinstance(action_input, dict):
                observation = "å·¥å…·å‚æ•°å¿…é¡»æ˜¯ JSON å¯¹è±¡ã€‚"
            else:
                try:
                    observation = tool.execute(action_input)
                except Exception as exc:  # noqa: BLE001 - å°†å·¥å…·é”™è¯¯ä¼ é€’ç»™ LLM
                    observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{exc}"

            step = Step(
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation,
                raw=raw,
            )
            steps.append(step)

            # æ›´æ–°è®¡åˆ’è¿›åº¦ï¼ˆå¦‚æœæœ‰è®¡åˆ’ï¼‰
            if plan and self.planner:
                # æŸ¥æ‰¾å½“å‰æ­¥éª¤å¯¹åº”çš„è®¡åˆ’æ­¥éª¤
                for plan_step in plan:
                    if plan_step.action == action and not plan_step.completed:
                        self.planner.mark_completed(plan_step.step_number, observation)
                        break

            # å°†å·¥å…·æ‰§è¡Œç»“æœæ·»åŠ åˆ°å†å²è®°å½•
            tool_info = f"æ‰§è¡Œå·¥å…· {action}ï¼Œè¾“å…¥ï¼š{json.dumps(action_input, ensure_ascii=False)}\nè§‚å¯Ÿï¼š{observation}"
            self.conversation_history.append({"role": "user", "content": tool_info})

            # è°ƒç”¨å›è°ƒå‡½æ•°å®æ—¶è¾“å‡ºæ­¥éª¤
            if self.step_callback:
                self.step_callback(step_num, step)

            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† task_complete å·¥å…·
            if action == "task_complete" and not observation.startswith("å·¥å…·æ‰§è¡Œå¤±è´¥"):
                return {
                    "final_answer": observation,
                    "steps": [step.__dict__ for step in steps],
                }

        return {
            "final_answer": "è¾¾åˆ°æ­¥éª¤é™åˆ¶ä½†æœªå®Œæˆã€‚",
            "steps": [step.__dict__ for step in steps],
        }

    def _build_user_prompt(self, task: str, steps: List[Step], plan: List[PlanStep] = None) -> str:
        lines = [f"ä»»åŠ¡ï¼š{task.strip()}"]

        # å¦‚æœæœ‰è®¡åˆ’ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
        if plan:
            lines.append("\næ‰§è¡Œè®¡åˆ’ï¼š")
            for plan_step in plan:
                status = "âœ“" if plan_step.completed else "â—‹"
                lines.append(f"{status} æ­¥éª¤ {plan_step.step_number}: {plan_step.action} - {plan_step.reason}")

        if steps:
            lines.append("\nä¹‹å‰çš„æ­¥éª¤ï¼š")
            for index, step in enumerate(steps, start=1):
                lines.append(f"æ­¥éª¤ {index} æ€è€ƒï¼š{step.thought}")
                lines.append(f"æ­¥éª¤ {index} åŠ¨ä½œï¼š{step.action}")
                lines.append(f"æ­¥éª¤ {index} è¾“å…¥ï¼š{json.dumps(step.action_input, ensure_ascii=False)}")
                lines.append(f"æ­¥éª¤ {index} è§‚å¯Ÿï¼š{step.observation}")
        lines.append(
            "\nç”¨ JSON å¯¹è±¡å›åº”ï¼š{\"thought\": string, \"action\": string, \"action_input\": object|string}ã€‚"
        )
        return "\n".join(lines)

    def _parse_agent_response(self, raw: str) -> Dict[str, Any]:
        candidate = raw.strip()
        if not candidate:
            raise ValueError("æ¨¡å‹è¿”å›ç©ºå“åº”ã€‚")
        try:
            parsed = json.loads(candidate)
        except json.JSONDecodeError:
            start = candidate.find("{")
            end = candidate.rfind("}")
            if start == -1 or end == -1 or end <= start:
                raise ValueError("å“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚")
            snippet = candidate[start : end + 1]
            parsed = json.loads(snippet)
        if not isinstance(parsed, dict):
            raise ValueError("æ™ºèƒ½ä½“å“åº”çš„ JSON å¿…é¡»æ˜¯å¯¹è±¡ã€‚")
        return parsed

    def reset_conversation(self) -> None:
        """é‡ç½®å¯¹è¯å†å²"""
        self.conversation_history = []

    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.copy()

    @staticmethod
    def _format_final_answer(action_input: Any) -> str:
        if isinstance(action_input, str):
            return action_input
        if isinstance(action_input, dict) and "answer" in action_input:
            value = action_input["answer"]
            if isinstance(value, str):
                return value
        return json.dumps(action_input, ensure_ascii=False)